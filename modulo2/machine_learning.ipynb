{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos preditivos de Machine Learning\n",
    "\n",
    "<img src='https://cms.qz.com/wp-content/uploads/2018/04/random-forest-animated-final-2.gif?w=410&h=270&strip=all&quality=75'/>\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Classificação e regressão são tarefas de aprendizagem supervisionada, **onde objetiva-se aprender um padrão de relação entre entrada e a saída**. \n",
    "- A  classificação é mais apropriada ao se trabalhar com saídas discretas (*e.g.*, ''sim'' ou ''não'');\n",
    "- A regressão, por outro lado, é indicada para problemas com saídas contínuas como um valor real, por exemplo.\n",
    "\n",
    "Tarefas de **agrupamento e associação** são consideradas pertencentes à aprendizagem não-supervisionada, ou seja, quando não há instâncias rotuladas na coleção.\n",
    "- Técnicas de agrupamento tentam identificar *clusters* com base nos atributos e/ou características dos dados;\n",
    "- Métodos de associação são projetados para identificar regras associativas entre as amostras como, por exemplo, ''*celulares mais vendidos com sistema operacional X*''.\n",
    "\n",
    "Neste módulo iremos estudar alguns métodos clássicos de *machine learning* pertencentes à <mark>aprendizagem supervisionada</mark>. Iremos focar, principalmente em técnias de classificação, abordando rapidamente a parte teórica a fim de proporcionar uma melhor explanação prática.\n",
    "\n",
    "### O que iremos ver?\n",
    "\n",
    "\n",
    "- Métodos\n",
    " - KNN *(from scratch)*\n",
    " - Naive Bayes *(using SkLearn)*\n",
    " - Árvores *(using SkLearn)*\n",
    "- Métricas & Avaliação de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos trabalhar com a coleção `jurassic.csv`. Vamos, então, deixar tudo prontinho..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic = pd.read_csv(\"jurassic.csv\")\n",
    "df_jurassic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não iremos precisar da coluna `Animal`, dessa forma, podemos remover do DataFrame com o método `pd.drop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic.drop(['Animal'], axis=1, inplace=True)\n",
    "df_jurassic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (K-NN)\n",
    "\n",
    "O KNN é um método baseado em **instâncias**! Esses métodos são muito simples e baseam-se na ideia de encontrar um conjunto pré-definido de casos de treino similares a uma nova instância (os vizinhos) e prever a nova instância com base neles.\n",
    "\n",
    "O tamanho da vizinhança pode ser tanto dada em termos de um número fixo $k$ quanto em termos de um raio de distância. A distância pode ser medida por qualquer métrica, por exemplo, a euclidiana. **Estes métodos não empregam técnicas de generalização já que eles lembram de todos os dados do treino.** \n",
    "\n",
    "> Dada a coleção `df_jurassic`, qual a classe da instância `{Era='Cretaceous', Dentes='V', Número de Asas=2, Penas Simétricas='V'}`, considerando $k$ = 1, 3, 5?\n",
    "\n",
    "Para isso, vamos utilizar a distância euclidiana:\n",
    "\n",
    "\n",
    "<img src='https://i1.wp.com/dataaspirant.com/wp-content/uploads/2015/04/euclidean.png' width='400'/>\n",
    "\n",
    "Ouuu...\n",
    "\n",
    "$$\n",
    "dist(a, b) = \\sqrt{ \\sum_{i=0}^{n}{d_i^2}  },\\\\\n",
    "d_i =\\begin{cases}\n",
    "    0, & \\text{se $a_i \\notin \\mathbb{R}$ e $a_i = b_i$}. \\\\\n",
    "    1, & \\text{se $a_i \\notin \\mathbb{R}$ e $a_i \\neq b_i$}. \\\\\n",
    "    a_i - b_i, & \\text{caso contrário}.\n",
    " \\end{cases}\n",
    "$$\n",
    "\n",
    "Neste caso, estamos assumindo que **a distância entre atributos simbólicos é 0** se eles têm os mesmos valores e 1, caso contrário. Convertendo para Python, temos:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    # Esta função irá ser executada para cada exemplo da coleção, linha por linha\n",
    "    summ = 0\n",
    "    \n",
    "    for i in range(len(a)): # Para cada atributo da linha, faça:\n",
    "        if isinstance(a[i], str): # Se o atributo for string...\n",
    "            val = 0 if a[i] == b[i] else 1 # `val` recebe 0 caso o atributo da coleção seja igual ao da instância ou 0, caso contrário.\n",
    "        else: # Caso o atributo não seja string, então apenas calcula a diferença\n",
    "            val = int(a[i]) - int(b[i])\n",
    "        \n",
    "        # Independente das condições acima, calcula o quadrado de `val`\n",
    "        # e acrescenta `val` ao acumulador/somatório `summ`\n",
    "        summ += val**2\n",
    "        \n",
    "    return np.sqrt(summ) # Retorna a raiz quadrada do somatório `summ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamo testar?\n",
    "\n",
    "Precisamos converter nossa instância (`{Era='Cretaceous', Dentes='V', Número de Asas=2, Penas Simétricas='V'}`) para um formato mais acessível à função `dist`, criada acima. Logo, trabalharemos com formatos de vetores do Numpy. \n",
    "\n",
    "Como resultado, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instancia = np.array(['Cretaceous', 'V', 2, 'V']) # Era, Dentes, Número de Asas, Penas Simétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show! Agora, basta aplicar a função `dist` para cada linha da nossa coleção `df_jurassic`, MAAASS, para testar, vamos passar apenas uma linha. Podemos usar `pd.iloc[]` para obter uma linha associada a um índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que o atributo `Ave` é o nosso alvo. Logo, não iremos passar ele. Devemos, então, mantermos apenas os mesmos atributos da instância (Era, Dentes, Número de Asas, Penas Simétricas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic.iloc[0][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaah, só pra fins de visualização, podemos deixar a saída do `pd.iloc` em um formato Numpy (pra ficar mais fácil de ver/comparar com a nossa instância):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df_jurassic.iloc[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar `dist` entre esses vetores para identificarmos a distância euclediana entre eles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist(df_jurassic.iloc[0][:-1], instancia)\n",
    "\n",
    "# Perceba que passar o `pd.iloc` no formato Numpy é SUPEEEER opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que calculamos nossa distância apenas para um exemplo da coleção... e deu um valorzinho bem alto rs\n",
    "\n",
    "Vamos agora calcular para TODAA a coleção `df_jurassic`? Neste caso, podemos usar (cautelosamente) o `pd.apply`  para passar cada linha à função `dist`.\n",
    "\n",
    "PS: `row` terá armazenará um `pd.Series`, bem parecido com o retorno do comando `pd.iloc`. Logo, devemos continuar pasando `[:-1]` para mantermos todos os atributos, exceto o último, `Ave`, que é o nosso alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucledian_dist = df_jurassic.apply(lambda row: dist(row[:-1], instancia), axis=1)\n",
    "eucledian_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos juntar `eucledian_dist` ao DataFrame para termos uma visualização melhor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic['distance'] = eucledian_dist\n",
    "df_jurassic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também ordenar a coleção pelo valor da dinstância:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic.sort_values('distance', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos obter os $K$ vizinhos mais próximos da nossa instância (`{Era='Cretaceous', Dentes='V', Número de Asas=2, Penas Simétricas='V'}`), basta selecionar as $K$ linhas do nosso DataFrame com a menor distância euclediana calculada. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jurassic.sort_values('distance', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos dizer que nossa instância, provalvemente, é da classe `{Ave='F'}`, uma vez que os indivíduos mais próximos a ela são também dessa classe.\n",
    "\n",
    "### Usando a implementação do KNN do Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos copiar nossa coleção original `df_jurassic` para um novo DataFrame chamdo `df_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_jurassic.iloc[:, :-1].copy()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usarmos o Scikit-Learn, devemos fazer alguns pequenos ajustes na nossa coleção. Primeiramente, iremos nos atentar aos tipos dos dados, visto que o SkLearn não é compatível com o formato `String`.\n",
    "\n",
    "Assim, utilizaremos a classe `LabelEncoder` para nos ajudar a codificar e decodificar os valores compatíveis com os modelos disponíveis no Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = {}\n",
    "\n",
    "for column in df_train.columns: # Para cada coluna do DataFrame\n",
    "    enc = LabelEncoder() # Instâncie um novo objeto LabelEncoder\n",
    "    df_train[column] = enc.fit_transform(df_train[column].astype(str)) # Codifique os valores dessa coluna\n",
    "    le[column] = enc # Salve o objeto numa tabela hash/dicionário cuja a chave seja o mesmo nome da coluna\n",
    "    \n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acessar o encoder de cada coluna, em `le`, e verificar as classes codificadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le['Era'].classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos deixar os atributos de treino explicitamente separados dos seus respectivos alvos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:, :-1] # Obtém todos os atributos, exceto a coluna \"Ave\"\n",
    "y = df_train['Ave'] # Seleciona apenas a coluna \"Ave\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ''treinar'' o KNN, com parêmetros próximos do que utilizamos na nossa implementação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "neigh.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos usar o método `KNeighborsClassifier.predict()` para inferirmos o alvo numa instância de teste.\n",
    "\n",
    "Aaah, lembra, que já temos uma instância \\o/ (`{Era='Cretaceous', Dentes='V', Número de Asas=2, Penas Simétricas='V'}`)... Ela está já no formato de arrays do Numpy na variável `instancia`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testarmos o nosso modelo do SkLearn, temos que aplicar o objeto `LabelEncoder` de cada coluna (que criamos mais cedo e armazenamos num dicionário) aos atributos da nossa instância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.full(len(instancia), np.nan, dtype=int)\n",
    "\n",
    "test[0] = le['Era'].transform([instancia[0]])[0]\n",
    "test[1] = le['Dentes'].transform([instancia[1]])[0]\n",
    "test[2] = le['Número de Asas'].transform([instancia[2]])[0]\n",
    "test[3] = le['Penas Simétricas'].transform([instancia[3]])[0]\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtermos o alvo, basta utilizarmos o método `predict`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict([test])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele irá nos devolver um `ŷ` que é um valor relacionado ao atributo `Ave`. Esse *output* é a previsão final do modelo, mas desse jeito ele está codificado. Podemos usar o encoder de Ave para verificarmos se nossa instância é ave ou não:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le['Ave'].inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, indexes = neigh.kneighbors([test])\n",
    "\n",
    "print(\"Distâncias:\", dist)\n",
    "print(\"Índices\", indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos até mesmo localizar os vizinhos mais próximos a nossa instância de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[indexes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas lembra que ainda tá codificado =/\n",
    "\n",
    "Vamos deixar legível :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X.loc[indexes[0]].copy()\n",
    "\n",
    "temp['Ave'] = y[indexes[0]]\n",
    "\n",
    "for col in temp.columns:\n",
    "    temp[col] = le[col].inverse_transform(temp[col])\n",
    "    \n",
    "temp['dist'] = dist[0]\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando novos métodos! =D\n",
    "\n",
    "Bem, agora que você já está familiarizado um pouquinho com a parte mais teórica/prática de machine learning, incluindo o Sk-Learn, vamos explorar alguns novos métodos?\n",
    "\n",
    "É bem importante conhecermos os principais tipos de modelos disponíveis lá... Bem como avaliarmos esses métodos. Vamos focar nisso comparando implementações de árvores de decisão e outras técnicas =D\n",
    "\n",
    "Assim, iremos utilizar a base pública [Titanic](https://www.kaggle.com/c/titanic/data), que já está no nosso repositório (`titanic.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv(\"titanic.csv\")\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre os atributos:\n",
    "\n",
    "\n",
    "- `PassengerId`: Unique ID of the passenger\n",
    "- `Survived`: Survived (1) or died (0)\n",
    "- `Pclass`: Passenger's class (1st, 2nd, or 3rd)\n",
    "- `Name`: Passenger's name\n",
    "- `Sex`: Passenger's sex\n",
    "- `Age`: Passenger's age\n",
    "- `SibSp`: Number of siblings/spouses aboard the Titanic\n",
    "- `Parch`: Number of parents/children aboard the Titanic\n",
    "- `Ticket`: Ticket number\n",
    "- `Fare`: Fare paid for ticket\n",
    "- `Cabin`: Cabin number\n",
    "- `Embarked`: Where the passenger got on the ship (C - Cherbourg, S - Southampton, Q = Queenstown)\n",
    "\n",
    "Perceba que a base contém vários tipos de dados (inteiros, reais, strings)... Vamos precisar fazer uma leve limpeza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Vamos excluir algumas colunas e também as linhas que não contém valores\n",
    "\n",
    "df_titanic.drop(['Name', 'Ticket', 'Fare', 'Cabin'], axis=1, inplace=True)\n",
    "df_titanic.dropna(inplace=True)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ficou:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos tentar consertar os tipos... Podemos usar o `LabelEncoder` ou o tipo `Category`, do próprio pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = {}\n",
    "\n",
    "for column in df_titanic.select_dtypes('object').columns:\n",
    "    print(\"Codificando coluna `%s`...\" % column)\n",
    "    \n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    df_titanic[column] = enc.fit_transform(df_titanic[column])\n",
    "    le[column] = enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar alguns gráficos? =D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"Passenger's sex\")\n",
    "df_titanic['Survived'].groupby(df_titanic['Sex']).sum().plot(kind='pie', explode=(0.15, 0), \n",
    "                                                             autopct=\"%.2f%%\", ax=ax[0])\n",
    "\n",
    "ax[1].set_title(\"Passenger's class\")\n",
    "df_titanic['Survived'].groupby(df_titanic['Pclass']).sum().plot(kind='pie', autopct=\"%.2f%%\", \n",
    "                                                                labels=['1st', '2nd', '3rd'],\n",
    "                                                                explode=(.05, .05, .05),\n",
    "                                                                ax=ax[1])\n",
    "ax[2].set_title(\"Where the passenger got on the ship\")\n",
    "df_titanic['Survived'].groupby(df_titanic['Embarked']).sum().plot(kind='pie', autopct=\"%.2f%%\", \n",
    "                                                                labels=['Cherbourg', 'Southampton', 'Queenstown'],\n",
    "                                                                explode=(.1, .1, .1), ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos os dados tratadinhos, podemos começar a explorar os métodos de ML. Existem várias técnicas disponíveis, [neste link](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) você pode conferir um *cheat-sheet* do próprio SkLearn.\n",
    "\n",
    "<img src='https://scikit-learn.org/stable/_static/ml_map.png' width='1024'/>\n",
    "\n",
    "Nesta aula, iremos comparar a performance de três modelos para o problema do Titanic.\n",
    "\n",
    "- Redes Neurais (rasas);\n",
    "- Árvore de decisão; e\n",
    "- Florestas Aleatórias.\n",
    "\n",
    "Lembre-se que o SkLearn, precisa que digamos quem são os atributos de treino ($X$) e o alvo ($y$) de forma explícita. Em tarefas de classificação precisaremos ter conjuntos de treino e teste (com seus respectivos alvos separados): \n",
    "\n",
    "- Treino: $X\\_train$, $y\\_train$\n",
    "- Teste: $X\\_test$, $y\\_test$\n",
    "\n",
    "Para nos ajudar a criar esses subconjuntos a partir da coleção `df_titanic`, usaremos o método [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df_titanic.drop([\"PassengerId\", \"Survived\"], axis=1)\n",
    "y = df_titanic[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos esses conjuntos para treinar ($X\\_train$, $y\\_train$) e testar ($X\\_test$, $y\\_test$) nossos modelos. A partir dos testes, poderemos observar a performance das técnicas e entender qual a que melhor se adequa ao nosso problema.\n",
    "\n",
    "\n",
    "#### Redes Neurais\n",
    "\n",
    "<center>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td><img src='https://camo.githubusercontent.com/8b87e593fb9382c16a81cc059d994adec259a1c4/687474703a2f2f692e696d6775722e636f6d2f643654374b39332e706e67' width='500'/></td>            \n",
    "            <td><img src='https://res.cloudinary.com/practicaldev/image/fetch/s--5DxkKcR3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/800/0%2AUHkKkn4dcN45xbAc.png' width='500'/></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(15, 90), activation='relu', solver='adam', \n",
    "                    max_iter=300, random_state=11)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos o modelo treinando, podemos fazer sua avaliação. Iremos utilizar a biblioteca [Scikit-plot](https://scikit-plot.readthedocs.io/en/stable/index.html) para nos ajudar nessa etapa.\n",
    "\n",
    "Com ela, teremos acesso a diversas métricas gráficas, vejamos:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Caso necessário, instale através do comando:\n",
    "\n",
    "! pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliarmos o nosso modelo, precisamos pedir pra ele realizar predições de teste (no nosso conjunto de teste $X\\_test$). Dessa forma, teremos um `ŷ` ($y\\_pred$) que será comparado com `y_true` ($y\\_test$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar com a Matriz de confusão.\n",
    "\n",
    "<img src='https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg' width='500'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Podemos também 'plotar' a CM de forma normalizada...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra métrica muito utilizada é a *Area Under the Curve (AUC)*, que é calculada a partir da curva ROC (*Receiver operating characteristic* -- Característica de Operação do Receptor). A curva ROC é importante por nos ajudar a entender a performance de um classificador e como o seu limiar de discriminação varia.\n",
    "\n",
    "<img src='https://miro.medium.com/max/722/1*pk05QGzoWhCgRiiFbz-oKQ.png' width='300'/>\n",
    "\n",
    "Para plotarmos nossa ROC Curve, precisamos obter as probabilidades de uma dada instância do nosso conjunto de teste pertencer a cada uma das classes. Ou seja, não poderemos utilizar o método `predict()`, agora, pois ele já nos devolve a classe provável da instância (ao invés de sua probabilidade). Observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felizmente, o Scikit-learn dispõe do método `predict_proba()` que nos devolve, para cada instância de teste, a probabilidade de tal instância pertencer a cada uma das possíveis classes. Vejamos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = clf.predict_proba(X_test)\n",
    "\n",
    "y_probas[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos nosso `y_proba`, podemos plotar a ROC Curve, usando a Scikit-plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sua vez! Treine, teste e avalie...\n",
    "\n",
    "- Árvore de Decisão (https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- Florestas Aleatórias (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
